<!-- hide -->
# RNA para clasificaci칩n de im치genes - Gu칤a paso a paso
<!-- endhide -->

- Comprender un dataset nuevo.
- Modelar los datos utilizando una RNA.
- Analizar los resultados y optimizar el modelo.

## 游꺔 C칩mo iniciar este proyecto

Sigue las siguientes instrucciones:

1. Crea un nuevo repositorio basado en el [proyecto de Machine Learning](https://github.com/4GeeksAcademy/machine-learning-python-template) o [haciendo clic aqu칤](https://github.com/4GeeksAcademy/machine-learning-python-template/generate).
2. Abre el repositorio creado recientemente en Codespace usando la [extensi칩n del bot칩n de Codespace](https://docs.github.com/en/codespaces/developing-in-codespaces/creating-a-codespace-for-a-repository#creating-a-codespace-for-a-repository).
3. Una vez que el VSCode del Codespace haya terminado de abrirse, comienza tu proyecto siguiendo las instrucciones a continuaci칩n.

## 游뚵 C칩mo entregar este proyecto

Una vez que hayas terminado de resolver el caso pr치ctico, aseg칰rate de confirmar tus cambios, haz push a tu repositorio y ve a 4Geeks.com para subir el enlace del repositorio.

## 游닇 Instrucciones

### Sistema de clasificaci칩n de im치genes

El conjunto de datos se compone de fotos de perros y gatos proporcionadas como un subconjunto de fotos de uno mucho m치s grande de 3 millones de fotos anotadas manualmente. Estos datos se obtuvieron a trav칠s de una colaboraci칩n entre Petfinder.com y Microsoft.

El conjunto de datos se us칩 originalmente como un CAPTCHA, es decir, una tarea que se cree que un humano encuentra trivial, pero que una m치quina no puede resolver, que se usa en sitios web para distinguir entre usuarios humanos y bots. La tarea se denomin칩 "Asirra". Cuando se present칩 "Asirra", se mencion칩 "que los estudios de usuarios indican que los humanos pueden resolverlo el 99,6% de las veces en menos de 30 segundos". A menos que se produzca un gran avance en la visi칩n artificial, esperamos que los ordenadores no tengan m치s de 1/54.000 posibilidades de resolverlo.

En el momento en que se public칩 la competencia, el resultado de 칰ltima generaci칩n se logr칩 con un SVM y se describi칩 en un art칤culo de 2007 con el t칤tulo "Ataques de Machine Learning contra el CAPTCHA de Asirra" (PDF) que logr칩 una precisi칩n de clasificaci칩n del 80%. Fue este documento el que demostr칩 que la tarea ya no era una tarea adecuada para un CAPTCHA poco despu칠s de que se propusiera la tarea.

#### Paso 1: Carga del conjunto de datos

El conjunto de datos se encuentra en Kaggle y tendr치s que acceder a ella para descargarlos. La competici칩n la puedes encontrar [aqu칤](https://www.kaggle.com/c/dogs-vs-cats/data) (o copiando y pegando el siguiente enlace en tu navegador: `https://www.kaggle.com/c/dogs-vs-cats/data`)

Descarga la carpeta dataset y descomprime los archivos. Ahora tendr치s una carpeta llamada `train` que contiene 25.000 archivos de imagen (formato .jpg) de perros y gatos. Las fotos est치n etiquetadas por su nombre de archivo, con la palabra `dog` o `cat`.

#### Paso 2: Visualiza la informaci칩n de entrada

El primer paso cuando nos enfrentamos a un problema de clasificaci칩n de im치genes es obtener toda la informaci칩n posible a trav칠s de ellas. Por lo tanto, carga e imprime las primeras nueve fotos de perros en una sola figura. Repite lo mismo para los gatos. Puedes ver que las fotos son a color y tienen diferentes formas y tama침os.

Esta variedad de tama침os y formatos debe solucionarse antes de entrenar el modelo. Aseg칰rate de que todas tengan un tama침o fijo de 200x200 p칤xeles.

Como podr치s ver, son una gran cantidad de im치genes, aseg칰rate de seguir las siguientes normas:

1. **Si tienes m치s de 12 gigabytes de RAM**, usa la API de procesamiento de im치genes de Keras para cargar las 25.000 fotos en el conjunto de datos de entrenamiento y remodelarlas a fotos cuadradas de 200칑200 p칤xeles. La etiqueta tambi칠n debe determinarse para cada foto en funci칩n de los nombres de archivo. Se debe guardar una tupla de fotos y etiquetas.
2. **Si no tienes m치s de 12 gigabytes de RAM**, carga las im치genes progresivamente usando la clase Keras `ImageDataGenerator` y la funci칩n `flow_from_directory()`. Esto ser치 m치s lento de ejecutar, pero se ejecutar치 en hardware de menor capacidad. Esta funci칩n prefiere que los datos se dividan en directorios *train* y *test* separados, y debajo de cada directorio para tener un subdirectorio para cada clase.

Una vez tengas todas las im치genes procesadas, crea un objeto `ImageDataGenerator` para datos de entrenamiento y prueba. Luego pasa la carpeta que tiene datos de entrenamiento al objeto `trdata` y, de manera similar, pasa la carpeta que tiene datos de prueba al objeto `tsdata`. De esta forma, se etiquetar치n las im치genes autom치ticamente y estar치 todo listo para entrar a la red.

#### Paso 3: Construye una RNA

Cualquier clasificador que se ajuste a este problema tendr치 que ser robusto porque algunas im치genes muestran al gato o al perro en una esquina o tal vez a 2 gatos o perros en la misma foto. Si has podido investigar algunas de las implementaciones de los ganadores de otras competiciones tambi칠n relacionadas con im치genes, ver치s que `VGG16` es una arquitectura de CNN utilizada para ganar la competencia de Kaggle ILSVR (Imagenet) en 2014. Se considera una de las arquitecturas de modelos de visi칩n con mejores resultados hasta la fecha.

Utiliza la siguiente arquitectura de prueba:

```py
model = Sequential()
model.add(Conv2D(input_shape = (224,224,3), filters = 64, kernel_size = (3,3), padding = "same", activation = "relu"))
model.add(Conv2D(filters = 64,kernel_size = (3,3),padding = "same", activation = "relu"))
model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))
model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = "same", activation = "relu"))
model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = "same", activation = "relu"))
model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))
model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = "same", activation = "relu"))
model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = "same", activation = "relu"))
model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = "same", activation = "relu"))
model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))
model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = "same", activation = "relu"))
model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = "same", activation = "relu"))
model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = "same", activation = "relu"))
model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))
model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = "same", activation = "relu"))
model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = "same", activation = "relu"))
model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = "same", activation = "relu"))
model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))
model.add(Flatten())
model.add(Dense(units = 4096,activation = "relu"))
model.add(Dense(units = 4096,activation = "relu"))
model.add(Dense(units = 2, activation = "softmax"))
```

El c칩digo anterior aplica convoluciones a los datos (capas `Conv2D` y `MaxPool2D`) y despu칠s aplica capas densas (capas `Dense`) para el procesamiento de los valores num칠ricos obtenidos tras las convoluciones.

A continuaci칩n a침ade los elementos restantes para conformar el modelo, entr칠nalo y mide su rendimiento.

#### Paso 4: Optimiza el modelo anterior

Importa el m칠todo `ModelCheckpoint` y `EarlyStopping` de Keras. Crea un objeto de ambos y p치salo como funciones callback a `fit_generator`.

Carga el mejor modelo de los anteriores y utiliza el conjunto de test para hacer predicciones.

#### Paso 5: Guarda el modelo

Almacena el modelo en la carpeta correspondiente.

> Nota: Tambi칠n incorporamos muestras de soluci칩n en `./solution.ipynb` que te sugerimos honestamente que solo uses si est치s atascado por m치s de 30 minutos o si ya has terminado y quieres compararlo con tu enfoque.
